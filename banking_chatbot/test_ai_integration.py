#!/usr/bin/env python3
"""
ğŸ§ª Test AI Integration - Banking Chatbot
UbicaciÃ³n: /test_ai_integration.py

Script para probar la integraciÃ³n completa de LLM + RAG
sin necesidad de ejecutar el servidor completo.
"""

import asyncio
import os
import sys
import json
from datetime import datetime
from pathlib import Path

# Agregar backend al path
backend_path = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_path))

# Configurar variables de entorno bÃ¡sicas
os.environ.setdefault("DEBUG", "True")
os.environ.setdefault("LLM_PROVIDER", "openai")
os.environ.setdefault("AI_ENABLED", "False")  # Empezar en modo fallback

async def test_chat_service():
    """
    ğŸ§ª Test bÃ¡sico del ChatService integrado
    """

    print("ğŸ§ª Testing ChatService con IA integrada...")

    try:
        # Importar servicios
        from services.chat.chat_service import ChatService

        # Inicializar servicio
        chat_service = ChatService()

        print("âœ… ChatService inicializado correctamente")

        # Test messages
        test_messages = [
            "Hola, Â¿cÃ³mo estÃ¡s?",
            "Quiero consultar mi saldo",
            "Â¿CÃ³mo puedo transferir dinero?",
            "Me robaron mi tarjeta, es urgente",
            "Â¿QuÃ© tipos de prÃ©stamos tienen?",
        ]

        print("\nğŸ”„ Ejecutando tests de mensajes...")

        for i, message in enumerate(test_messages, 1):
            print(f"\n--- Test {i}/5 ---")
            print(f"ğŸ“ Usuario: {message}")

            # Procesar mensaje
            response = await chat_service.process_message(
                message=message,
                session_id=f"test_session_{i}",
                user_id="test_user"
            )

            print(f"ğŸ¤– Bot ({response['confidence']}): {response['message'][:100]}...")
            print(f"âš¡ Tiempo: {response.get('processing_time_ms', 0)}ms")
            print(f"ğŸ¯ MÃ©todo: {response.get('metadata', {}).get('processing_method', 'unknown')}")

            if response.get('suggested_actions'):
                print(f"ğŸ’¡ Acciones: {response['suggested_actions']}")

            if response.get('escalate_to_human'):
                print("ğŸ‘¤ Requiere escalaciÃ³n humana")

        # Test analytics
        print(f"\nğŸ“Š Testing analytics...")
        analytics = await chat_service.get_analytics()
        print(f"   - Llamadas IA: {analytics.get('ai_metrics', {}).get('ai_calls', 0)}")
        print(f"   - Llamadas fallback: {analytics.get('ai_metrics', {}).get('fallback_calls', 0)}")

        # Test health check
        print(f"\nğŸ¥ Testing health check...")
        health = await chat_service.get_service_health()
        print(f"   - Estado: {health.get('chat_service')}")
        print(f"   - IA habilitada: {health.get('ai_mode_enabled')}")

        print("\nâœ… Todos los tests de ChatService pasaron!")
        return True

    except Exception as e:
        print(f"âŒ Error en test de ChatService: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

async def test_llm_service():
    """
    ğŸ§ª Test del LLM Service
    """

    print("\nğŸ¤– Testing LLM Service...")

    try:
        from services.llm.llm_service import LLMService

        llm_service = LLMService()
        print("âœ… LLM Service inicializado")

        # Test disponibilidad de proveedores
        providers = await llm_service.get_available_providers()
        print(f"ğŸ”Œ Proveedores disponibles: {providers}")

        if not providers:
            print("âš ï¸  Sin proveedores LLM disponibles (modo fallback)")
            return True

        # Test generaciÃ³n de respuesta
        print("\nğŸ§  Testing generaciÃ³n de respuesta...")
        response = await llm_service.generate_response(
            user_message="Â¿CuÃ¡l es el lÃ­mite de transferencia?",
            session_id="test_llm_session"
        )

        print(f"ğŸ“ Respuesta generada: {response.get('message', 'No message')[:100]}...")
        print(f"ğŸ¯ Confianza: {response.get('confidence', 'unknown')}")
        print(f"âš¡ Tiempo: {response.get('processing_time_seconds', 0):.2f}s")

        # Test estadÃ­sticas
        stats = await llm_service.get_usage_stats()
        print(f"ğŸ“Š Stats - Total tokens: {stats.get('total_tokens_used', 0)}")

        print("âœ… LLM Service test completado!")
        return True

    except Exception as e:
        print(f"âŒ Error en test de LLM Service: {str(e)}")
        return False

async def test_rag_service():
    """
    ğŸ§ª Test del RAG Service
    """

    print("\nğŸ” Testing RAG Service...")

    try:
        from services.rag.rag_service import RAGService

        rag_service = RAGService()
        print("âœ… RAG Service inicializado")

        # Test bÃºsqueda de documentos
        print("\nğŸ“š Testing bÃºsqueda de documentos...")
        docs = await rag_service.retrieve_relevant_documents(
            query="transferencias bancarias lÃ­mites",
            top_k=3
        )

        print(f"ğŸ“„ Documentos encontrados: {len(docs)}")
        for i, doc in enumerate(docs, 1):
            print(f"   {i}. {doc.get('title', 'Sin tÃ­tulo')[:50]}... (Score: {doc.get('similarity_score', 0):.2f})")

        # Test contexto para LLM
        print("\nğŸ§  Testing contexto para LLM...")
        context = await rag_service.get_context_for_llm("Â¿CÃ³mo transferir dinero?")
        print(f"ğŸ“ Contexto generado: {len(context)} caracteres")

        # Test estadÃ­sticas de KB
        stats = await rag_service.get_knowledge_stats()
        print(f"ğŸ“Š KB Stats - Docs: {stats.get('total_documents', 0)}, CategorÃ­as: {len(stats.get('categories', []))}")

        print("âœ… RAG Service test completado!")
        return True

    except Exception as e:
        print(f"âŒ Error en test de RAG Service: {str(e)}")
        return False

async def main():
    """
    ğŸš€ Ejecutar todos los tests
    """

    print("ğŸ¦ Banking Chatbot - Test de IntegraciÃ³n IA")
    print("=" * 50)

    results = []

    # Test ChatService (principal)
    results.append(await test_chat_service())

    # Test LLM Service
    results.append(await test_llm_service())

    # Test RAG Service
    results.append(await test_rag_service())

    # Resumen
    print("\n" + "=" * 50)
    print("ğŸ“‹ RESUMEN DE TESTS")
    print("=" * 50)

    test_names = ["ChatService", "LLM Service", "RAG Service"]
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} {name}")

    passed = sum(results)
    total = len(results)

    print(f"\nğŸ† Resultado: {passed}/{total} tests pasaron")

    if passed == total:
        print("ğŸ‰ Â¡IntegraciÃ³n IA completamente funcional!")
        return 0
    else:
        print("âš ï¸  Algunos tests fallaron - revisar logs arriba")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)